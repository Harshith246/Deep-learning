{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "## Shallow Neural network in Keras\n\nBuild a shallow Neural network in Keras to identify the apparels. \n\n", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "#### set seed for reproducability", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "import numpy as np\nnp.random.seed(42)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 1
        }, 
        {
            "source": "#### Load dependencies", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "import keras\nfrom keras.datasets import fashion_mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import SGD", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "Using TensorFlow backend.\n"
                }
            ], 
            "execution_count": 2
        }, 
        {
            "source": "#### load Data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "\n(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n32768/29515 [=================================] - 0s 4us/step\nDownloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n26427392/26421880 [==============================] - 21s 1us/step\nDownloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n8192/5148 [===============================================] - 0s 0us/step\nDownloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n4423680/4422102 [==============================] - 1s 0us/step\n"
                }
            ], 
            "execution_count": 3
        }, 
        {
            "source": "X_train.shape", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "(60000, 28, 28)"
                    }, 
                    "execution_count": 5, 
                    "metadata": {}
                }
            ], 
            "execution_count": 5
        }, 
        {
            "source": "y_train.shape", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "(60000,)"
                    }, 
                    "execution_count": 7, 
                    "metadata": {}
                }
            ], 
            "execution_count": 7
        }, 
        {
            "source": "X_test.shape", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "(10000, 28, 28)"
                    }, 
                    "execution_count": 8, 
                    "metadata": {}
                }
            ], 
            "execution_count": 8
        }, 
        {
            "source": "y_test.shape", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "(10000,)"
                    }, 
                    "execution_count": 9, 
                    "metadata": {}
                }
            ], 
            "execution_count": 9
        }, 
        {
            "source": "y_train[0:10]", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "array([9, 0, 0, 3, 0, 2, 7, 2, 5, 5], dtype=uint8)"
                    }, 
                    "execution_count": 10, 
                    "metadata": {}
                }
            ], 
            "execution_count": 10
        }, 
        {
            "source": "X_test[0]", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   3,   1,   0,   0,   7,   0,  37,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          1,   2,   0,  27,  84,  11,   0,   0,   0,   0,   0,   0, 119,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          1,   0,   0,  88, 143, 110,   0,   0,   0,   0,  22,  93, 106,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          4,   0,  53, 129, 120, 147, 175, 157, 166, 135, 154, 168, 140,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   2,\n          0,  11, 137, 130, 128, 160, 176, 159, 167, 178, 149, 151, 144,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   1,   0,   2,   1,   0,   3,   0,\n          0, 115, 114, 106, 137, 168, 153, 156, 165, 167, 143, 157, 158,\n         11,   0],\n       [  0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   3,   0,   0,\n         89, 139,  90,  94, 153, 149, 131, 151, 169, 172, 143, 159, 169,\n         48,   0],\n       [  0,   0,   0,   0,   0,   0,   2,   4,   1,   0,   0,   0,  98,\n        136, 110, 109, 110, 162, 135, 144, 149, 159, 167, 144, 158, 169,\n        119,   0],\n       [  0,   0,   2,   2,   1,   2,   0,   0,   0,   0,  26, 108, 117,\n         99, 111, 117, 136, 156, 134, 154, 154, 156, 160, 141, 147, 156,\n        178,   0],\n       [  3,   0,   0,   0,   0,   0,   0,  21,  53,  92, 117, 111, 103,\n        115, 129, 134, 143, 154, 165, 170, 154, 151, 154, 143, 138, 150,\n        165,  43],\n       [  0,   0,  23,  54,  65,  76,  85, 118, 128, 123, 111, 113, 118,\n        127, 125, 139, 133, 136, 160, 140, 155, 161, 144, 155, 172, 161,\n        189,  62],\n       [  0,  68,  94,  90, 111, 114, 111, 114, 115, 127, 135, 136, 143,\n        126, 127, 151, 154, 143, 148, 125, 162, 162, 144, 138, 153, 162,\n        196,  58],\n       [ 70, 169, 129, 104,  98, 100,  94,  97,  98, 102, 108, 106, 119,\n        120, 129, 149, 156, 167, 190, 190, 196, 198, 198, 187, 197, 189,\n        184,  36],\n       [ 16, 126, 171, 188, 188, 184, 171, 153, 135, 120, 126, 127, 146,\n        185, 195, 209, 208, 255, 209, 177, 245, 252, 251, 251, 247, 220,\n        206,  49],\n       [  0,   0,   0,  12,  67, 106, 164, 185, 199, 210, 211, 210, 208,\n        190, 150,  82,   8,   0,   0,   0, 178, 208, 188, 175, 162, 158,\n        151,  11],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0]], dtype=uint8)"
                    }, 
                    "execution_count": 11, 
                    "metadata": {}
                }
            ], 
            "execution_count": 11
        }, 
        {
            "source": "y_test[0]", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "9"
                    }, 
                    "execution_count": 12, 
                    "metadata": {}
                }
            ], 
            "execution_count": 12
        }, 
        {
            "source": "#### Preprocess data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "X_train = X_train.reshape(60000, 784).astype('float32')\nX_test = X_test.reshape(10000, 784).astype('float32')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 13
        }, 
        {
            "source": "\nX_train /= 255\nX_test /= 255", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 14
        }, 
        {
            "source": "\nX_test[0]", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.01176471,  0.00392157,  0.        ,  0.        ,  0.02745098,\n        0.        ,  0.14509805,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.00392157,  0.00784314,  0.        ,\n        0.10588235,  0.32941177,  0.04313726,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.46666667,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.00392157,  0.        ,  0.        ,  0.34509805,  0.56078434,\n        0.43137255,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.08627451,  0.36470589,  0.41568628,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.01568628,  0.        ,\n        0.20784314,  0.50588238,  0.47058824,  0.57647061,  0.68627453,\n        0.6156863 ,  0.65098041,  0.52941179,  0.60392159,  0.65882355,\n        0.54901963,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.00784314,  0.        ,  0.04313726,  0.53725493,  0.50980395,\n        0.50196081,  0.627451  ,  0.6901961 ,  0.62352943,  0.65490198,\n        0.69803923,  0.58431375,  0.59215689,  0.56470591,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.00392157,  0.        ,  0.00784314,\n        0.00392157,  0.        ,  0.01176471,  0.        ,  0.        ,\n        0.4509804 ,  0.44705883,  0.41568628,  0.53725493,  0.65882355,\n        0.60000002,  0.61176473,  0.64705884,  0.65490198,  0.56078434,\n        0.6156863 ,  0.61960787,  0.04313726,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.00392157,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.01176471,\n        0.        ,  0.        ,  0.34901962,  0.54509807,  0.35294119,\n        0.36862746,  0.60000002,  0.58431375,  0.51372552,  0.59215689,\n        0.66274512,  0.67450982,  0.56078434,  0.62352943,  0.66274512,\n        0.1882353 ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.00784314,  0.01568628,\n        0.00392157,  0.        ,  0.        ,  0.        ,  0.38431373,\n        0.53333336,  0.43137255,  0.42745098,  0.43137255,  0.63529414,\n        0.52941179,  0.56470591,  0.58431375,  0.62352943,  0.65490198,\n        0.56470591,  0.61960787,  0.66274512,  0.46666667,  0.        ,\n        0.        ,  0.        ,  0.00784314,  0.00784314,  0.00392157,\n        0.00784314,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.10196079,  0.42352942,  0.45882353,  0.3882353 ,  0.43529412,\n        0.45882353,  0.53333336,  0.61176473,  0.52549022,  0.60392159,\n        0.60392159,  0.61176473,  0.627451  ,  0.5529412 ,  0.57647061,\n        0.61176473,  0.69803923,  0.        ,  0.01176471,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.08235294,  0.20784314,  0.36078432,  0.45882353,  0.43529412,\n        0.40392157,  0.4509804 ,  0.50588238,  0.52549022,  0.56078434,\n        0.60392159,  0.64705884,  0.66666669,  0.60392159,  0.59215689,\n        0.60392159,  0.56078434,  0.5411765 ,  0.58823532,  0.64705884,\n        0.16862746,  0.        ,  0.        ,  0.09019608,  0.21176471,\n        0.25490198,  0.29803923,  0.33333334,  0.4627451 ,  0.50196081,\n        0.48235294,  0.43529412,  0.44313726,  0.4627451 ,  0.49803922,\n        0.49019608,  0.54509807,  0.52156866,  0.53333336,  0.627451  ,\n        0.54901963,  0.60784316,  0.63137257,  0.56470591,  0.60784316,\n        0.67450982,  0.63137257,  0.74117649,  0.24313726,  0.        ,\n        0.26666668,  0.36862746,  0.35294119,  0.43529412,  0.44705883,\n        0.43529412,  0.44705883,  0.4509804 ,  0.49803922,  0.52941179,\n        0.53333336,  0.56078434,  0.49411765,  0.49803922,  0.59215689,\n        0.60392159,  0.56078434,  0.58039218,  0.49019608,  0.63529414,\n        0.63529414,  0.56470591,  0.5411765 ,  0.60000002,  0.63529414,\n        0.76862746,  0.22745098,  0.27450982,  0.66274512,  0.50588238,\n        0.40784314,  0.38431373,  0.39215687,  0.36862746,  0.38039216,\n        0.38431373,  0.40000001,  0.42352942,  0.41568628,  0.46666667,\n        0.47058824,  0.50588238,  0.58431375,  0.61176473,  0.65490198,\n        0.74509805,  0.74509805,  0.76862746,  0.7764706 ,  0.7764706 ,\n        0.73333335,  0.77254903,  0.74117649,  0.72156864,  0.14117648,\n        0.0627451 ,  0.49411765,  0.67058825,  0.73725492,  0.73725492,\n        0.72156864,  0.67058825,  0.60000002,  0.52941179,  0.47058824,\n        0.49411765,  0.49803922,  0.57254905,  0.72549021,  0.7647059 ,\n        0.81960785,  0.81568629,  1.        ,  0.81960785,  0.69411767,\n        0.96078432,  0.98823529,  0.98431373,  0.98431373,  0.96862745,\n        0.86274511,  0.80784315,  0.19215687,  0.        ,  0.        ,\n        0.        ,  0.04705882,  0.26274511,  0.41568628,  0.64313728,\n        0.72549021,  0.78039217,  0.82352942,  0.82745099,  0.82352942,\n        0.81568629,  0.74509805,  0.58823532,  0.32156864,  0.03137255,\n        0.        ,  0.        ,  0.        ,  0.69803923,  0.81568629,\n        0.73725492,  0.68627453,  0.63529414,  0.61960787,  0.59215689,\n        0.04313726,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32)"
                    }, 
                    "execution_count": 15, 
                    "metadata": {}
                }
            ], 
            "execution_count": 15
        }, 
        {
            "source": "n_classes = 10\ny_train = keras.utils.to_categorical(y_train, n_classes)\ny_test = keras.utils.to_categorical(y_test, n_classes)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 16
        }, 
        {
            "source": "\ny_test[0:2]", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
                    }, 
                    "execution_count": 18, 
                    "metadata": {}
                }
            ], 
            "execution_count": 18
        }, 
        {
            "source": "#### Design Nueral Network Architecture ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "\nmodel = Sequential()\nmodel.add(Dense(64, activation='sigmoid', input_shape=(784,)))\nmodel.add(Dense(10, activation='softmax'))\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 19
        }, 
        {
            "source": "model.summary()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 64)                50240     \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                650       \n=================================================================\nTotal params: 50,890\nTrainable params: 50,890\nNon-trainable params: 0\n_________________________________________________________________\n"
                }
            ], 
            "execution_count": 20
        }, 
        {
            "source": "#### Configure Model", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "\nmodel.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01), metrics=['accuracy'])", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 21
        }, 
        {
            "source": "#### Train the Model", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "model.fit(X_train, y_train, batch_size=128, epochs=200, verbose=1, validation_data=(X_test, y_test))", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Train on 60000 samples, validate on 10000 samples\nEpoch 1/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0917 - acc: 0.0356 - val_loss: 0.0910 - val_acc: 0.0258\nEpoch 2/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0905 - acc: 0.0610 - val_loss: 0.0900 - val_acc: 0.1188\nEpoch 3/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0896 - acc: 0.1758 - val_loss: 0.0892 - val_acc: 0.2214\nEpoch 4/200\n60000/60000 [==============================] - 5s 83us/step - loss: 0.0888 - acc: 0.2484 - val_loss: 0.0885 - val_acc: 0.2720\nEpoch 5/200\n60000/60000 [==============================] - 5s 83us/step - loss: 0.0881 - acc: 0.2939 - val_loss: 0.0878 - val_acc: 0.3120\nEpoch 6/200\n60000/60000 [==============================] - 5s 88us/step - loss: 0.0874 - acc: 0.3272 - val_loss: 0.0871 - val_acc: 0.3409\nEpoch 7/200\n60000/60000 [==============================] - 5s 84us/step - loss: 0.0867 - acc: 0.3501 - val_loss: 0.0864 - val_acc: 0.3587\nEpoch 8/200\n60000/60000 [==============================] - 5s 85us/step - loss: 0.0861 - acc: 0.3633 - val_loss: 0.0858 - val_acc: 0.3690\nEpoch 9/200\n60000/60000 [==============================] - 5s 78us/step - loss: 0.0854 - acc: 0.3711 - val_loss: 0.0851 - val_acc: 0.3729\nEpoch 10/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0847 - acc: 0.3717 - val_loss: 0.0844 - val_acc: 0.3752\nEpoch 11/200\n60000/60000 [==============================] - 5s 81us/step - loss: 0.0840 - acc: 0.3742 - val_loss: 0.0837 - val_acc: 0.3719\nEpoch 12/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0834 - acc: 0.3720 - val_loss: 0.0830 - val_acc: 0.3719\nEpoch 13/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0827 - acc: 0.3742 - val_loss: 0.0824 - val_acc: 0.3740\nEpoch 14/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0820 - acc: 0.3772 - val_loss: 0.0817 - val_acc: 0.3800\nEpoch 15/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0813 - acc: 0.3840 - val_loss: 0.0810 - val_acc: 0.3874\nEpoch 16/200\n60000/60000 [==============================] - 5s 79us/step - loss: 0.0806 - acc: 0.3934 - val_loss: 0.0802 - val_acc: 0.3957\nEpoch 17/200\n60000/60000 [==============================] - 5s 83us/step - loss: 0.0798 - acc: 0.4038 - val_loss: 0.0795 - val_acc: 0.4034\nEpoch 18/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0791 - acc: 0.4111 - val_loss: 0.0788 - val_acc: 0.4158\nEpoch 19/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0784 - acc: 0.4237 - val_loss: 0.0781 - val_acc: 0.4267\nEpoch 20/200\n60000/60000 [==============================] - 5s 85us/step - loss: 0.0777 - acc: 0.4335 - val_loss: 0.0774 - val_acc: 0.4384\nEpoch 21/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0770 - acc: 0.4456 - val_loss: 0.0767 - val_acc: 0.4514\nEpoch 22/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0763 - acc: 0.4561 - val_loss: 0.0760 - val_acc: 0.4626\nEpoch 23/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0755 - acc: 0.4649 - val_loss: 0.0753 - val_acc: 0.4752\nEpoch 24/200\n60000/60000 [==============================] - 5s 84us/step - loss: 0.0748 - acc: 0.4789 - val_loss: 0.0746 - val_acc: 0.4862\nEpoch 25/200\n60000/60000 [==============================] - 5s 87us/step - loss: 0.0742 - acc: 0.4874 - val_loss: 0.0739 - val_acc: 0.4973\nEpoch 26/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0735 - acc: 0.4987 - val_loss: 0.0732 - val_acc: 0.5060\nEpoch 27/200\n60000/60000 [==============================] - 5s 83us/step - loss: 0.0728 - acc: 0.5074 - val_loss: 0.0726 - val_acc: 0.5149\nEpoch 28/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0721 - acc: 0.5168 - val_loss: 0.0719 - val_acc: 0.5232\nEpoch 29/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0715 - acc: 0.5237 - val_loss: 0.0713 - val_acc: 0.5305\nEpoch 30/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0708 - acc: 0.5318 - val_loss: 0.0706 - val_acc: 0.5377\nEpoch 31/200\n60000/60000 [==============================] - 5s 79us/step - loss: 0.0702 - acc: 0.5385 - val_loss: 0.0700 - val_acc: 0.5450\nEpoch 32/200\n60000/60000 [==============================] - 5s 78us/step - loss: 0.0696 - acc: 0.5446 - val_loss: 0.0694 - val_acc: 0.5501\nEpoch 33/200\n60000/60000 [==============================] - 5s 78us/step - loss: 0.0689 - acc: 0.5503 - val_loss: 0.0688 - val_acc: 0.5565\nEpoch 34/200\n60000/60000 [==============================] - 5s 87us/step - loss: 0.0683 - acc: 0.5583 - val_loss: 0.0682 - val_acc: 0.5607\nEpoch 35/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0677 - acc: 0.5653 - val_loss: 0.0676 - val_acc: 0.5663\nEpoch 36/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0672 - acc: 0.5715 - val_loss: 0.0670 - val_acc: 0.5728\nEpoch 37/200\n60000/60000 [==============================] - 5s 78us/step - loss: 0.0666 - acc: 0.5787 - val_loss: 0.0664 - val_acc: 0.5785\nEpoch 38/200\n60000/60000 [==============================] - 5s 78us/step - loss: 0.0660 - acc: 0.5833 - val_loss: 0.0659 - val_acc: 0.5849\nEpoch 39/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0654 - acc: 0.5908 - val_loss: 0.0653 - val_acc: 0.5902\nEpoch 40/200\n60000/60000 [==============================] - 5s 83us/step - loss: 0.0649 - acc: 0.5957 - val_loss: 0.0648 - val_acc: 0.5951\nEpoch 41/200\n60000/60000 [==============================] - 5s 79us/step - loss: 0.0644 - acc: 0.6021 - val_loss: 0.0643 - val_acc: 0.5997\nEpoch 42/200\n60000/60000 [==============================] - 5s 77us/step - loss: 0.0638 - acc: 0.6068 - val_loss: 0.0637 - val_acc: 0.6035\nEpoch 43/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0633 - acc: 0.6120 - val_loss: 0.0632 - val_acc: 0.6084\nEpoch 44/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0628 - acc: 0.6160 - val_loss: 0.0627 - val_acc: 0.6130\nEpoch 45/200\n60000/60000 [==============================] - 5s 81us/step - loss: 0.0623 - acc: 0.6206 - val_loss: 0.0622 - val_acc: 0.6174\nEpoch 46/200\n60000/60000 [==============================] - 5s 88us/step - loss: 0.0618 - acc: 0.6251 - val_loss: 0.0617 - val_acc: 0.6211\nEpoch 47/200\n60000/60000 [==============================] - 5s 87us/step - loss: 0.0613 - acc: 0.6290 - val_loss: 0.0613 - val_acc: 0.6239\nEpoch 48/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0608 - acc: 0.6325 - val_loss: 0.0608 - val_acc: 0.6280\nEpoch 49/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0603 - acc: 0.6357 - val_loss: 0.0603 - val_acc: 0.6320\nEpoch 50/200\n60000/60000 [==============================] - 5s 78us/step - loss: 0.0598 - acc: 0.6383 - val_loss: 0.0599 - val_acc: 0.6352\nEpoch 51/200\n60000/60000 [==============================] - 5s 84us/step - loss: 0.0594 - acc: 0.6421 - val_loss: 0.0594 - val_acc: 0.6390\nEpoch 52/200\n60000/60000 [==============================] - 5s 78us/step - loss: 0.0589 - acc: 0.6441 - val_loss: 0.0590 - val_acc: 0.6412\nEpoch 53/200\n60000/60000 [==============================] - 5s 77us/step - loss: 0.0585 - acc: 0.6468 - val_loss: 0.0585 - val_acc: 0.6439\nEpoch 54/200\n60000/60000 [==============================] - 5s 77us/step - loss: 0.0580 - acc: 0.6493 - val_loss: 0.0581 - val_acc: 0.6466\nEpoch 55/200\n60000/60000 [==============================] - 5s 75us/step - loss: 0.0576 - acc: 0.6518 - val_loss: 0.0577 - val_acc: 0.6498\nEpoch 56/200\n60000/60000 [==============================] - 5s 78us/step - loss: 0.0572 - acc: 0.6538 - val_loss: 0.0572 - val_acc: 0.6514\nEpoch 57/200\n60000/60000 [==============================] - 4s 75us/step - loss: 0.0567 - acc: 0.6566 - val_loss: 0.0568 - val_acc: 0.6531\nEpoch 58/200\n60000/60000 [==============================] - 5s 78us/step - loss: 0.0563 - acc: 0.6593 - val_loss: 0.0564 - val_acc: 0.6546\nEpoch 59/200\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "60000/60000 [==============================] - 5s 81us/step - loss: 0.0559 - acc: 0.6629 - val_loss: 0.0560 - val_acc: 0.6572\nEpoch 60/200\n60000/60000 [==============================] - 5s 77us/step - loss: 0.0555 - acc: 0.6653 - val_loss: 0.0556 - val_acc: 0.6603\nEpoch 61/200\n60000/60000 [==============================] - 5s 77us/step - loss: 0.0551 - acc: 0.6680 - val_loss: 0.0553 - val_acc: 0.6631\nEpoch 62/200\n60000/60000 [==============================] - 5s 75us/step - loss: 0.0547 - acc: 0.6710 - val_loss: 0.0549 - val_acc: 0.6657\nEpoch 63/200\n60000/60000 [==============================] - 5s 88us/step - loss: 0.0544 - acc: 0.6738 - val_loss: 0.0545 - val_acc: 0.6687\nEpoch 64/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0540 - acc: 0.6762 - val_loss: 0.0541 - val_acc: 0.6708\nEpoch 65/200\n60000/60000 [==============================] - 6s 96us/step - loss: 0.0536 - acc: 0.6785 - val_loss: 0.0538 - val_acc: 0.6729\nEpoch 66/200\n60000/60000 [==============================] - 5s 79us/step - loss: 0.0533 - acc: 0.6812 - val_loss: 0.0534 - val_acc: 0.6759\nEpoch 67/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0529 - acc: 0.6834 - val_loss: 0.0531 - val_acc: 0.6774\nEpoch 68/200\n60000/60000 [==============================] - 5s 90us/step - loss: 0.0526 - acc: 0.6856 - val_loss: 0.0528 - val_acc: 0.6789\nEpoch 69/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0522 - acc: 0.6882 - val_loss: 0.0524 - val_acc: 0.6813\nEpoch 70/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0519 - acc: 0.6899 - val_loss: 0.0521 - val_acc: 0.6828\nEpoch 71/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0516 - acc: 0.6926 - val_loss: 0.0518 - val_acc: 0.6850\nEpoch 72/200\n60000/60000 [==============================] - 5s 81us/step - loss: 0.0513 - acc: 0.6940 - val_loss: 0.0515 - val_acc: 0.6877\nEpoch 73/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0509 - acc: 0.6956 - val_loss: 0.0512 - val_acc: 0.6891\nEpoch 74/200\n60000/60000 [==============================] - 5s 83us/step - loss: 0.0506 - acc: 0.6978 - val_loss: 0.0509 - val_acc: 0.6909\nEpoch 75/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0503 - acc: 0.6993 - val_loss: 0.0506 - val_acc: 0.6929\nEpoch 76/200\n60000/60000 [==============================] - 5s 85us/step - loss: 0.0500 - acc: 0.7012 - val_loss: 0.0503 - val_acc: 0.6941\nEpoch 77/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0498 - acc: 0.7026 - val_loss: 0.0500 - val_acc: 0.6955\nEpoch 78/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0495 - acc: 0.7042 - val_loss: 0.0497 - val_acc: 0.6970\nEpoch 79/200\n60000/60000 [==============================] - 5s 83us/step - loss: 0.0492 - acc: 0.7059 - val_loss: 0.0495 - val_acc: 0.6987\nEpoch 80/200\n60000/60000 [==============================] - 5s 83us/step - loss: 0.0489 - acc: 0.7072 - val_loss: 0.0492 - val_acc: 0.7002\nEpoch 81/200\n60000/60000 [==============================] - 5s 86us/step - loss: 0.0486 - acc: 0.7086 - val_loss: 0.0489 - val_acc: 0.7013\nEpoch 82/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0484 - acc: 0.7100 - val_loss: 0.0487 - val_acc: 0.7026\nEpoch 83/200\n60000/60000 [==============================] - 5s 85us/step - loss: 0.0481 - acc: 0.7110 - val_loss: 0.0484 - val_acc: 0.7036\nEpoch 84/200\n60000/60000 [==============================] - 5s 81us/step - loss: 0.0479 - acc: 0.7123 - val_loss: 0.0482 - val_acc: 0.7045\nEpoch 85/200\n60000/60000 [==============================] - 5s 79us/step - loss: 0.0476 - acc: 0.7131 - val_loss: 0.0479 - val_acc: 0.7051\nEpoch 86/200\n60000/60000 [==============================] - 5s 83us/step - loss: 0.0474 - acc: 0.7143 - val_loss: 0.0477 - val_acc: 0.7050\nEpoch 87/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0471 - acc: 0.7153 - val_loss: 0.0475 - val_acc: 0.7066\nEpoch 88/200\n60000/60000 [==============================] - 5s 78us/step - loss: 0.0469 - acc: 0.7163 - val_loss: 0.0473 - val_acc: 0.7078\nEpoch 89/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0467 - acc: 0.7171 - val_loss: 0.0470 - val_acc: 0.7083\nEpoch 90/200\n60000/60000 [==============================] - 5s 79us/step - loss: 0.0465 - acc: 0.7178 - val_loss: 0.0468 - val_acc: 0.7084\nEpoch 91/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0462 - acc: 0.7184 - val_loss: 0.0466 - val_acc: 0.7092\nEpoch 92/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0460 - acc: 0.7194 - val_loss: 0.0464 - val_acc: 0.7099\nEpoch 93/200\n60000/60000 [==============================] - 5s 87us/step - loss: 0.0458 - acc: 0.7203 - val_loss: 0.0462 - val_acc: 0.7105\nEpoch 94/200\n60000/60000 [==============================] - 5s 79us/step - loss: 0.0456 - acc: 0.7210 - val_loss: 0.0460 - val_acc: 0.7124\nEpoch 95/200\n60000/60000 [==============================] - 5s 81us/step - loss: 0.0454 - acc: 0.7217 - val_loss: 0.0458 - val_acc: 0.7127\nEpoch 96/200\n60000/60000 [==============================] - 5s 85us/step - loss: 0.0452 - acc: 0.7222 - val_loss: 0.0456 - val_acc: 0.7140\nEpoch 97/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0450 - acc: 0.7229 - val_loss: 0.0454 - val_acc: 0.7149\nEpoch 98/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0448 - acc: 0.7236 - val_loss: 0.0452 - val_acc: 0.7159\nEpoch 99/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0446 - acc: 0.7242 - val_loss: 0.0450 - val_acc: 0.7168\nEpoch 100/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0444 - acc: 0.7247 - val_loss: 0.0448 - val_acc: 0.7179\nEpoch 101/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0442 - acc: 0.7256 - val_loss: 0.0446 - val_acc: 0.7187\nEpoch 102/200\n60000/60000 [==============================] - 5s 89us/step - loss: 0.0441 - acc: 0.7263 - val_loss: 0.0445 - val_acc: 0.7194\nEpoch 103/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0439 - acc: 0.7266 - val_loss: 0.0443 - val_acc: 0.7201\nEpoch 104/200\n60000/60000 [==============================] - 5s 83us/step - loss: 0.0437 - acc: 0.7271 - val_loss: 0.0441 - val_acc: 0.7207\nEpoch 105/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0435 - acc: 0.7279 - val_loss: 0.0440 - val_acc: 0.7209\nEpoch 106/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0434 - acc: 0.7287 - val_loss: 0.0438 - val_acc: 0.7212\nEpoch 107/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0432 - acc: 0.7292 - val_loss: 0.0436 - val_acc: 0.7219\nEpoch 108/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0430 - acc: 0.7300 - val_loss: 0.0435 - val_acc: 0.7230\nEpoch 109/200\n60000/60000 [==============================] - 5s 87us/step - loss: 0.0429 - acc: 0.7303 - val_loss: 0.0433 - val_acc: 0.7236\nEpoch 110/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0427 - acc: 0.7308 - val_loss: 0.0432 - val_acc: 0.7241\nEpoch 111/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0426 - acc: 0.7314 - val_loss: 0.0430 - val_acc: 0.7246\nEpoch 112/200\n60000/60000 [==============================] - 5s 86us/step - loss: 0.0424 - acc: 0.7320 - val_loss: 0.0429 - val_acc: 0.7250\nEpoch 113/200\n60000/60000 [==============================] - 5s 78us/step - loss: 0.0422 - acc: 0.7326 - val_loss: 0.0427 - val_acc: 0.7251\nEpoch 114/200\n60000/60000 [==============================] - 5s 78us/step - loss: 0.0421 - acc: 0.7330 - val_loss: 0.0426 - val_acc: 0.7261\nEpoch 115/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0420 - acc: 0.7336 - val_loss: 0.0424 - val_acc: 0.7268\nEpoch 116/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0418 - acc: 0.7341 - val_loss: 0.0423 - val_acc: 0.7275\nEpoch 117/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0417 - acc: 0.7348 - val_loss: 0.0422 - val_acc: 0.7280\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Epoch 118/200\n60000/60000 [==============================] - 5s 81us/step - loss: 0.0415 - acc: 0.7352 - val_loss: 0.0420 - val_acc: 0.7291\nEpoch 119/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0414 - acc: 0.7357 - val_loss: 0.0419 - val_acc: 0.7292\nEpoch 120/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0413 - acc: 0.7360 - val_loss: 0.0418 - val_acc: 0.7296\nEpoch 121/200\n60000/60000 [==============================] - 5s 92us/step - loss: 0.0411 - acc: 0.7367 - val_loss: 0.0416 - val_acc: 0.7297\nEpoch 122/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0410 - acc: 0.7369 - val_loss: 0.0415 - val_acc: 0.7302\nEpoch 123/200\n60000/60000 [==============================] - 5s 85us/step - loss: 0.0409 - acc: 0.7374 - val_loss: 0.0414 - val_acc: 0.7307\nEpoch 124/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0407 - acc: 0.7380 - val_loss: 0.0412 - val_acc: 0.7309\nEpoch 125/200\n60000/60000 [==============================] - 5s 78us/step - loss: 0.0406 - acc: 0.7382 - val_loss: 0.0411 - val_acc: 0.7313\nEpoch 126/200\n60000/60000 [==============================] - 5s 87us/step - loss: 0.0405 - acc: 0.7389 - val_loss: 0.0410 - val_acc: 0.7320\nEpoch 127/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0404 - acc: 0.7394 - val_loss: 0.0409 - val_acc: 0.7323\nEpoch 128/200\n60000/60000 [==============================] - 5s 78us/step - loss: 0.0402 - acc: 0.7395 - val_loss: 0.0408 - val_acc: 0.7327\nEpoch 129/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0401 - acc: 0.7403 - val_loss: 0.0407 - val_acc: 0.7328\nEpoch 130/200\n60000/60000 [==============================] - 5s 84us/step - loss: 0.0400 - acc: 0.7405 - val_loss: 0.0405 - val_acc: 0.7341\nEpoch 131/200\n60000/60000 [==============================] - 5s 81us/step - loss: 0.0399 - acc: 0.7412 - val_loss: 0.0404 - val_acc: 0.7342\nEpoch 132/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0398 - acc: 0.7416 - val_loss: 0.0403 - val_acc: 0.7345\nEpoch 133/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0397 - acc: 0.7419 - val_loss: 0.0402 - val_acc: 0.7352\nEpoch 134/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0396 - acc: 0.7425 - val_loss: 0.0401 - val_acc: 0.7356\nEpoch 135/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0394 - acc: 0.7432 - val_loss: 0.0400 - val_acc: 0.7358\nEpoch 136/200\n60000/60000 [==============================] - 5s 85us/step - loss: 0.0393 - acc: 0.7435 - val_loss: 0.0399 - val_acc: 0.7364\nEpoch 137/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0392 - acc: 0.7440 - val_loss: 0.0398 - val_acc: 0.7364\nEpoch 138/200\n60000/60000 [==============================] - 5s 79us/step - loss: 0.0391 - acc: 0.7444 - val_loss: 0.0397 - val_acc: 0.7365\nEpoch 139/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0390 - acc: 0.7449 - val_loss: 0.0396 - val_acc: 0.7368\nEpoch 140/200\n60000/60000 [==============================] - 5s 90us/step - loss: 0.0389 - acc: 0.7452 - val_loss: 0.0395 - val_acc: 0.7377\nEpoch 141/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0388 - acc: 0.7456 - val_loss: 0.0394 - val_acc: 0.7373\nEpoch 142/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0387 - acc: 0.7457 - val_loss: 0.0393 - val_acc: 0.7381\nEpoch 143/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0386 - acc: 0.7464 - val_loss: 0.0392 - val_acc: 0.7386\nEpoch 144/200\n60000/60000 [==============================] - 5s 83us/step - loss: 0.0385 - acc: 0.7467 - val_loss: 0.0391 - val_acc: 0.7390\nEpoch 145/200\n60000/60000 [==============================] - 5s 79us/step - loss: 0.0384 - acc: 0.7474 - val_loss: 0.0390 - val_acc: 0.7391\nEpoch 146/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0383 - acc: 0.7477 - val_loss: 0.0389 - val_acc: 0.7396\nEpoch 147/200\n60000/60000 [==============================] - 5s 83us/step - loss: 0.0382 - acc: 0.7481 - val_loss: 0.0388 - val_acc: 0.7396\nEpoch 148/200\n60000/60000 [==============================] - 5s 78us/step - loss: 0.0382 - acc: 0.7484 - val_loss: 0.0388 - val_acc: 0.7403\nEpoch 149/200\n60000/60000 [==============================] - 5s 77us/step - loss: 0.0381 - acc: 0.7489 - val_loss: 0.0387 - val_acc: 0.7408\nEpoch 150/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0380 - acc: 0.7492 - val_loss: 0.0386 - val_acc: 0.7410\nEpoch 151/200\n60000/60000 [==============================] - 5s 75us/step - loss: 0.0379 - acc: 0.7493 - val_loss: 0.0385 - val_acc: 0.7419\nEpoch 152/200\n60000/60000 [==============================] - 5s 75us/step - loss: 0.0378 - acc: 0.7497 - val_loss: 0.0384 - val_acc: 0.7421\nEpoch 153/200\n60000/60000 [==============================] - 4s 75us/step - loss: 0.0377 - acc: 0.7501 - val_loss: 0.0383 - val_acc: 0.7422\nEpoch 154/200\n60000/60000 [==============================] - 5s 77us/step - loss: 0.0376 - acc: 0.7505 - val_loss: 0.0383 - val_acc: 0.7426\nEpoch 155/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0375 - acc: 0.7510 - val_loss: 0.0382 - val_acc: 0.7426\nEpoch 156/200\n60000/60000 [==============================] - 4s 73us/step - loss: 0.0375 - acc: 0.7513 - val_loss: 0.0381 - val_acc: 0.7427\nEpoch 157/200\n60000/60000 [==============================] - 4s 73us/step - loss: 0.0374 - acc: 0.7520 - val_loss: 0.0380 - val_acc: 0.7437\nEpoch 158/200\n60000/60000 [==============================] - 4s 75us/step - loss: 0.0373 - acc: 0.7524 - val_loss: 0.0379 - val_acc: 0.7439\nEpoch 159/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0372 - acc: 0.7528 - val_loss: 0.0379 - val_acc: 0.7434\nEpoch 160/200\n60000/60000 [==============================] - 4s 75us/step - loss: 0.0371 - acc: 0.7533 - val_loss: 0.0378 - val_acc: 0.7440\nEpoch 161/200\n60000/60000 [==============================] - 5s 78us/step - loss: 0.0371 - acc: 0.7539 - val_loss: 0.0377 - val_acc: 0.7442\nEpoch 162/200\n60000/60000 [==============================] - 4s 73us/step - loss: 0.0370 - acc: 0.7541 - val_loss: 0.0376 - val_acc: 0.7447\nEpoch 163/200\n60000/60000 [==============================] - 4s 75us/step - loss: 0.0369 - acc: 0.7546 - val_loss: 0.0376 - val_acc: 0.7453\nEpoch 164/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0368 - acc: 0.7550 - val_loss: 0.0375 - val_acc: 0.7460\nEpoch 165/200\n60000/60000 [==============================] - 5s 79us/step - loss: 0.0367 - acc: 0.7553 - val_loss: 0.0374 - val_acc: 0.7467\nEpoch 166/200\n60000/60000 [==============================] - 5s 81us/step - loss: 0.0367 - acc: 0.7560 - val_loss: 0.0373 - val_acc: 0.7470\nEpoch 167/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0366 - acc: 0.7564 - val_loss: 0.0373 - val_acc: 0.7471\nEpoch 168/200\n60000/60000 [==============================] - 5s 79us/step - loss: 0.0365 - acc: 0.7566 - val_loss: 0.0372 - val_acc: 0.7473\nEpoch 169/200\n60000/60000 [==============================] - 5s 91us/step - loss: 0.0365 - acc: 0.7571 - val_loss: 0.0371 - val_acc: 0.7475\nEpoch 170/200\n60000/60000 [==============================] - 6s 97us/step - loss: 0.0364 - acc: 0.7576 - val_loss: 0.0371 - val_acc: 0.7476\nEpoch 171/200\n60000/60000 [==============================] - 5s 85us/step - loss: 0.0363 - acc: 0.7579 - val_loss: 0.0370 - val_acc: 0.7477\nEpoch 172/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0362 - acc: 0.7582 - val_loss: 0.0369 - val_acc: 0.7482\nEpoch 173/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0362 - acc: 0.7588 - val_loss: 0.0369 - val_acc: 0.7483\nEpoch 174/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0361 - acc: 0.7591 - val_loss: 0.0368 - val_acc: 0.7491\nEpoch 175/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0360 - acc: 0.7596 - val_loss: 0.0367 - val_acc: 0.7492\nEpoch 176/200\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "60000/60000 [==============================] - 5s 81us/step - loss: 0.0360 - acc: 0.7599 - val_loss: 0.0367 - val_acc: 0.7496\nEpoch 177/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0359 - acc: 0.7605 - val_loss: 0.0366 - val_acc: 0.7495\nEpoch 178/200\n60000/60000 [==============================] - 5s 78us/step - loss: 0.0358 - acc: 0.7606 - val_loss: 0.0365 - val_acc: 0.7498\nEpoch 179/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0358 - acc: 0.7611 - val_loss: 0.0365 - val_acc: 0.7498\nEpoch 180/200\n60000/60000 [==============================] - 5s 81us/step - loss: 0.0357 - acc: 0.7615 - val_loss: 0.0364 - val_acc: 0.7505\nEpoch 181/200\n60000/60000 [==============================] - 5s 87us/step - loss: 0.0356 - acc: 0.7617 - val_loss: 0.0364 - val_acc: 0.7506\nEpoch 182/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0356 - acc: 0.7621 - val_loss: 0.0363 - val_acc: 0.7514\nEpoch 183/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0355 - acc: 0.7625 - val_loss: 0.0362 - val_acc: 0.7517\nEpoch 184/200\n60000/60000 [==============================] - 5s 88us/step - loss: 0.0355 - acc: 0.7630 - val_loss: 0.0362 - val_acc: 0.7514\nEpoch 185/200\n60000/60000 [==============================] - 5s 85us/step - loss: 0.0354 - acc: 0.7633 - val_loss: 0.0361 - val_acc: 0.7518\nEpoch 186/200\n60000/60000 [==============================] - 5s 83us/step - loss: 0.0353 - acc: 0.7638 - val_loss: 0.0361 - val_acc: 0.7522\nEpoch 187/200\n60000/60000 [==============================] - 5s 83us/step - loss: 0.0353 - acc: 0.7641 - val_loss: 0.0360 - val_acc: 0.7525\nEpoch 188/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0352 - acc: 0.7647 - val_loss: 0.0359 - val_acc: 0.7538\nEpoch 189/200\n60000/60000 [==============================] - 5s 82us/step - loss: 0.0352 - acc: 0.7648 - val_loss: 0.0359 - val_acc: 0.7542\nEpoch 190/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0351 - acc: 0.7652 - val_loss: 0.0358 - val_acc: 0.7546\nEpoch 191/200\n60000/60000 [==============================] - 5s 85us/step - loss: 0.0350 - acc: 0.7656 - val_loss: 0.0358 - val_acc: 0.7552\nEpoch 192/200\n60000/60000 [==============================] - 5s 79us/step - loss: 0.0350 - acc: 0.7659 - val_loss: 0.0357 - val_acc: 0.7561\nEpoch 193/200\n60000/60000 [==============================] - 5s 79us/step - loss: 0.0349 - acc: 0.7663 - val_loss: 0.0357 - val_acc: 0.7565\nEpoch 194/200\n60000/60000 [==============================] - 5s 78us/step - loss: 0.0349 - acc: 0.7663 - val_loss: 0.0356 - val_acc: 0.7570\nEpoch 195/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0348 - acc: 0.7668 - val_loss: 0.0356 - val_acc: 0.7578\nEpoch 196/200\n60000/60000 [==============================] - 5s 86us/step - loss: 0.0348 - acc: 0.7672 - val_loss: 0.0355 - val_acc: 0.7584\nEpoch 197/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0347 - acc: 0.7675 - val_loss: 0.0355 - val_acc: 0.7586\nEpoch 198/200\n60000/60000 [==============================] - 5s 87us/step - loss: 0.0346 - acc: 0.7678 - val_loss: 0.0354 - val_acc: 0.7586\nEpoch 199/200\n60000/60000 [==============================] - 5s 80us/step - loss: 0.0346 - acc: 0.7683 - val_loss: 0.0354 - val_acc: 0.7588\nEpoch 200/200\n60000/60000 [==============================] - 5s 86us/step - loss: 0.0345 - acc: 0.7686 - val_loss: 0.0353 - val_acc: 0.7591\n"
                }, 
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "<keras.callbacks.History at 0x7fcb571404a8>"
                    }, 
                    "execution_count": 22, 
                    "metadata": {}
                }
            ], 
            "execution_count": 22
        }, 
        {
            "source": "\nmodel.evaluate(X_test, y_test)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "10000/10000 [==============================] - 0s 48us/step\n"
                }, 
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "[0.035298771125078204, 0.7591]"
                    }, 
                    "execution_count": 23, 
                    "metadata": {}
                }
            ], 
            "execution_count": 23
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.5", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}